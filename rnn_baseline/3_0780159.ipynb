{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba817a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from itertools import combinations\n",
    "import time\n",
    "import pandas as pd\n",
    "from data_generators import batches_generator\n",
    "\n",
    "\n",
    "import lightgbm as lgb \n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335bc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = ['./test_buckets_rnn/processed_chunk_000.pkl']\n",
    "dataset_test = ['../data/7Folds/test_buckets_rnn/processed_chunk_000.pkl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2062cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data.pickle', 'rb') as f:\n",
    "#    data_new = pickle.load(f)\n",
    "\n",
    "i=6                                  \n",
    "\n",
    "depo_path = '../data/depo/'\n",
    "with open(os.path.join(depo_path,  \"y_val_pred_parts_net2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_pred_parts_net, f)    \n",
    "            y_val_pred_parts_net2 = pickle.load(f)        \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_test_preds_net2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_test_preds_net, f)    \n",
    "            y_test_preds_net2 = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_val_true_parts_net2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_true_parts_net, f)   \n",
    "            y_val_true_parts_net2 = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"cut_list_net2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(cut_list_net, f)    \n",
    "            cut_list_net2 = pickle.load(f)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "with open(os.path.join(depo_path,  \"y_val_pred_parts_net_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_pred_parts_net, f)    \n",
    "            y_val_pred_parts_net = pickle.load(f)        \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_test_preds_net_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_test_preds_net, f)    \n",
    "            y_test_preds_net = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_val_true_parts_net_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_true_parts_net, f)   \n",
    "            y_val_true_parts_net = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"cut_list_net_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(cut_list_net, f)    \n",
    "            cut_list_net = pickle.load(f)    \n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_val_pred_parts_lgbm_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_pred_parts_net, f)    \n",
    "            y_val_pred_parts_lgbm = pickle.load(f)        \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_test_preds_lgbm_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_test_preds_net, f)    \n",
    "            y_test_preds_lgbm = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_val_true_parts_lgbm_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_true_parts_net, f)   \n",
    "            y_val_true_parts_lgbm = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"cut_list_lgbm_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(cut_list_net, f)    \n",
    "            cut_list_lgbm = pickle.load(f)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "with open(os.path.join(depo_path,  \"y_val_pred_parts_lgbm2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_pred_parts_net, f)    \n",
    "            y_val_pred_parts_lgbm2 = pickle.load(f)        \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_test_preds_lgbm2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_test_preds_net, f)    \n",
    "            y_test_preds_lgbm2 = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"y_val_true_parts_lgbm2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(y_val_true_parts_net, f)   \n",
    "            y_val_true_parts_lgbm2 = pickle.load(f)            \n",
    "\n",
    "with open(os.path.join(depo_path,  \"cut_list_lgbm2_Fold_\"+str(i)+\".h5\"), \"rb\") as f:\n",
    "            #pickle.dump(cut_list_net, f)    \n",
    "            cut_list_lgbm2 = pickle.load(f)    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83807d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c9c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgbm_result_level2(x, y, test_enc):\n",
    "    global cls_model\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_enc, train_y, val_enc, val_y = x[:400000], y[:400000], x[400000:], y[400000:]\n",
    "    \n",
    "    \n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\", # gbdt goss\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"learning_rate\": 0.001,  # 0.003,\n",
    "        \"n_jobs\": 8,\n",
    "        \"seed\": 15,\n",
    "        \"max_depth\": 5,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    dtrain = lgb.Dataset(\n",
    "        data=train_enc, label=train_y, free_raw_data=False\n",
    "    )\n",
    "    dvalid = lgb.Dataset(\n",
    "        data=val_enc,  label=val_y, free_raw_data=False\n",
    "    )\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    def lgboost_optimize_params(num_leaves, \n",
    "                                feature_fraction, \n",
    "                                bagging_fraction,\n",
    "                                max_depth,\n",
    "                               ):\n",
    "\n",
    "        params[\"num_leaves\"] = int(num_leaves)\n",
    "        params[\"feature_fraction\"] = feature_fraction\n",
    "        params[\"bagging_fraction\"] = bagging_fraction\n",
    "        params[\"max_depth\"] = int(max_depth)       \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=50, #1500,\n",
    "            valid_sets=[dtrain, dvalid],\n",
    "            categorical_feature=\"auto\",\n",
    "            early_stopping_rounds=250,\n",
    "            #verbose_eval=10,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "       \n",
    "        \n",
    "        \n",
    "        return roc_auc_score(val_y, model.predict(val_enc))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    params_search={\n",
    "                    'num_leaves': (24, 45),\n",
    "                    'feature_fraction': (0.1, 0.8),\n",
    "                    'bagging_fraction': (0.8, 1),\n",
    "                    'max_depth': (4, 13),\n",
    "                   }\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    lgb_params_search = BayesianOptimization(\n",
    "        lgboost_optimize_params,\n",
    "        pbounds=params_search,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgb_params_search.maximize(\n",
    "        init_points=5, n_iter=5 #, acq='ei'\n",
    "    )                                                    \n",
    "                                                    \n",
    "    optimal_lgb_params = lgb_params_search.max                                                \n",
    "\n",
    "    print(optimal_lgb_params['params'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for key in optimal_lgb_params['params']:\n",
    "        print(key, optimal_lgb_params['params'][key])\n",
    "        params[key] = optimal_lgb_params['params'][key]\n",
    "    print()\n",
    "    \n",
    "    params['max_depth'] = int((params['max_depth']).round())\n",
    "    params['num_leaves'] = int((params['num_leaves']).round())\n",
    "    print('================new params==================')\n",
    "    print(params)    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cls_model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=7500,  #00,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        categorical_feature=\"auto\",\n",
    "        early_stopping_rounds=300,\n",
    "        verbose_eval=100,\n",
    "        #verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    #ypred_train = cls_model.predict(train_enc)\n",
    "    ypred_valid = cls_model.predict(val_enc)\n",
    "    ypred_test = cls_model.predict(test_enc)\n",
    "\n",
    "\n",
    "    print('roc_auc_score:', roc_auc_score(val_y, ypred_valid))\n",
    "    print('lgb pass ==========================================')\n",
    "    print()\n",
    "    \n",
    "    return ypred_valid, ypred_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7880c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(cut_list, y_val_pred_list, y_test_preds_list, y_val_true_list, dataset_test): #   \n",
    "    \n",
    "    #dataset_test = None\n",
    "    y_val_pred_parts, y_test_preds, y_val_true_parts = y_val_pred_list.copy(), y_test_preds_list.copy(), y_val_true_list.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    k_list=[]\n",
    "    for i in range(len(cut_list)):\n",
    "        k = 0.5/cut_list[i]\n",
    "        k_list.append(k)\n",
    "\n",
    "    print(k_list)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(y_val_pred_parts)):\n",
    "        y_val_pred_parts[i] = y_val_pred_parts[i]*k_list[i]\n",
    "\n",
    "    for i in range(len(y_test_preds)):\n",
    "        y_test_preds[i] = y_test_preds[i]*k_list[i]\n",
    "\n",
    "\n",
    "\n",
    "    y_end  =y_test_preds[0]\n",
    "    y      =y_val_true_parts[0].reshape(-1,1)\n",
    "    y_vpred=y_val_pred_parts[0].reshape(-1,1)\n",
    "\n",
    "\n",
    "    for i in range(1,len(y_val_true_parts)):\n",
    "        y_val_true_parts[i]=y_val_true_parts[i].reshape(-1,1)\n",
    "        y_val_pred_parts[i]=y_val_pred_parts[i].reshape(-1,1)  \n",
    "        y=np.vstack((y,y_val_true_parts[i]))\n",
    "        y_vpred=np.vstack((y_vpred,y_val_pred_parts[i]))  \n",
    "\n",
    "\n",
    "        \n",
    "    for i in range(1,len(y_test_preds)):\n",
    "        y_end         = y_end*y_test_preds[i]\n",
    "    y_end      = y_end**(1/len(y_test_preds))\n",
    "\n",
    "\n",
    "    if dataset_test is None:\n",
    "        test_preds = None\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        test_generator = batches_generator(dataset_test, batch_size=128, shuffle=False,\n",
    "                                           is_train=False, output_format=\"tf\")\n",
    "\n",
    "\n",
    "        ids=[]\n",
    "        for _, batch_ids in test_generator:\n",
    "            ids.extend(batch_ids)\n",
    "\n",
    "        test_preds = pd.DataFrame({\"id\": ids, \"score\": y_end})\n",
    "    \n",
    "    print('Final ROC AUC:    ', roc_auc_score(y, y_vpred))\n",
    "    \n",
    "    return y, y_vpred, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5462e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dics_results(models_dic):\n",
    "    models_list = list(models_dic.keys())\n",
    "    result_dic ={}\n",
    "    for n in [4,3,2]:\n",
    "        for i in combinations(models_list, n):\n",
    "            result_1 = 1\n",
    "            result_2 = 0\n",
    "            name1 = 'mul_'\n",
    "            name2 = 'sum_'        \n",
    "            for j in i:\n",
    "                result_1 = result_1 * models_dic[j]\n",
    "                result_2 = result_2 + models_dic[j]            \n",
    "                name1 = name1 + j +'_'\n",
    "                name2 = name2 + j +'_'    \n",
    "                \n",
    "            result_1 = (result_1)**(1/len(i))   \n",
    "            result_2 = result_2 / len(i)  \n",
    "            #print(i) # ab ac ad bc bd cd       \n",
    "            #print(name1, ':', result_1)\n",
    "            #print(name2, ':', result_2)\n",
    "            result_dic[name1] = result_1\n",
    "            result_dic[name2] = result_2\n",
    "\n",
    "\n",
    "            #print('=====================================')\n",
    "    z = result_dic.update(models_dic)\n",
    "    return result_dic\n",
    "\n",
    "\n",
    "def get_scores(y_valid, result_dic):\n",
    "    scores_dic ={}\n",
    "    best = 0.\n",
    "    for i in result_dic:        \n",
    "        scor  = roc_auc_score(y_valid, result_dic[i])\n",
    "        scores_dic[i] = scor\n",
    "        if scor > best:\n",
    "            best = scor\n",
    "            name = i   \n",
    "        #print(i, result_dic[i])\n",
    "    #print()    \n",
    "    #print(name, best)\n",
    "    return name, scores_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d9924e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_lstm_st1_lstm_st2_ 0.7877827284819685\n",
      "{'mul_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7874302453893292, 'sum_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7875082834300686, 'mul_lstm_st1_lstm_st2_net_st1_': 0.7874371927700773, 'sum_lstm_st1_lstm_st2_net_st1_': 0.7874769743875492, 'mul_lstm_st1_lstm_st2_net_st2_': 0.7873013550018668, 'sum_lstm_st1_lstm_st2_net_st2_': 0.7873748206481088, 'mul_lstm_st1_net_st1_net_st2_': 0.7867662941438007, 'sum_lstm_st1_net_st1_net_st2_': 0.7868088785925528, 'mul_lstm_st2_net_st1_net_st2_': 0.7867094219983816, 'sum_lstm_st2_net_st1_net_st2_': 0.7868156756536798, 'mul_lstm_st1_lstm_st2_': 0.7877827284819685, 'sum_lstm_st1_lstm_st2_': 0.7877819156720556, 'mul_lstm_st1_net_st1_': 0.7855003380019571, 'sum_lstm_st1_net_st1_': 0.785461193529263, 'mul_lstm_st1_net_st2_': 0.7867670624795098, 'sum_lstm_st1_net_st2_': 0.7868370718903069, 'mul_lstm_st2_net_st1_': 0.7867505185538747, 'sum_lstm_st2_net_st1_': 0.7868033685734412, 'mul_lstm_st2_net_st2_': 0.7854435226049844, 'sum_lstm_st2_net_st2_': 0.7855216774901377, 'mul_net_st1_net_st2_': 0.7855546874716992, 'sum_net_st1_net_st2_': 0.7855810055999279, 'lstm_st1': 0.7857269951232482, 'lstm_st2': 0.7856896031573559, 'net_st1': 0.7818612151462768, 'net_st2': 0.7828422524017952}\n",
      "\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7751  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7747  \u001b[0m | \u001b[0m 0.8312  \u001b[0m | \u001b[0m 0.2092  \u001b[0m | \u001b[0m 4.523   \u001b[0m | \u001b[0m 42.19   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7751  \u001b[0m | \u001b[0m 0.9202  \u001b[0m | \u001b[0m 0.5957  \u001b[0m | \u001b[0m 4.185   \u001b[0m | \u001b[0m 44.37   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7746  \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 5.636   \u001b[0m | \u001b[0m 27.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.775   \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7751  \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 0.5201  \u001b[0m | \u001b[0m 4.209   \u001b[0m | \u001b[0m 44.42   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.775   \u001b[0m | \u001b[0m 0.8885  \u001b[0m | \u001b[0m 0.7681  \u001b[0m | \u001b[0m 9.514   \u001b[0m | \u001b[0m 34.45   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7746  \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 0.1835  \u001b[0m | \u001b[0m 12.58   \u001b[0m | \u001b[0m 35.49   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7751  \u001b[0m | \u001b[0m 0.9041  \u001b[0m | \u001b[0m 0.6325  \u001b[0m | \u001b[0m 9.015   \u001b[0m | \u001b[0m 36.44   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.775   \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 0.7845  \u001b[0m | \u001b[0m 9.864   \u001b[0m | \u001b[0m 38.48   \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.8749080237694725, 'feature_fraction': 0.7655000144869414, 'max_depth': 10.587945476302647, 'num_leaves': 36.57182816813777}\n",
      "bagging_fraction 0.8749080237694725\n",
      "feature_fraction 0.7655000144869414\n",
      "max_depth 10.587945476302647\n",
      "num_leaves 36.57182816813777\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 11, 'verbose': -1, 'num_leaves': 37, 'feature_fraction': 0.7655000144869414, 'bagging_fraction': 0.8749080237694725}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.790185\tvalid_1's auc: 0.774987\n",
      "[200]\ttraining's auc: 0.790556\tvalid_1's auc: 0.774682\n",
      "[300]\ttraining's auc: 0.791263\tvalid_1's auc: 0.775026\n",
      "[400]\ttraining's auc: 0.79154\tvalid_1's auc: 0.775142\n",
      "[500]\ttraining's auc: 0.791888\tvalid_1's auc: 0.775098\n",
      "[600]\ttraining's auc: 0.792132\tvalid_1's auc: 0.775164\n",
      "[700]\ttraining's auc: 0.79242\tvalid_1's auc: 0.775111\n",
      "[800]\ttraining's auc: 0.792721\tvalid_1's auc: 0.775059\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's auc: 0.792011\tvalid_1's auc: 0.77522\n",
      "roc_auc_score: 0.7752199325296545\n",
      "lgb pass ==========================================\n",
      "\n",
      "Fold: 0 pass. Time 34.071842193603516 sec.\n",
      "=======================================================================================================\n",
      "\n",
      "\n",
      "mul_lstm_st1_lstm_st2_ 0.7910344630133903\n",
      "{'mul_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7904495589894901, 'sum_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7905425168106475, 'mul_lstm_st1_lstm_st2_net_st1_': 0.7906999107926638, 'sum_lstm_st1_lstm_st2_net_st1_': 0.7907266010736755, 'mul_lstm_st1_lstm_st2_net_st2_': 0.7901169616796165, 'sum_lstm_st1_lstm_st2_net_st2_': 0.790318608225353, 'mul_lstm_st1_net_st1_net_st2_': 0.7900299235292207, 'sum_lstm_st1_net_st1_net_st2_': 0.7900702303867442, 'mul_lstm_st2_net_st1_net_st2_': 0.7892147015688658, 'sum_lstm_st2_net_st1_net_st2_': 0.789334143573383, 'mul_lstm_st1_lstm_st2_': 0.7910344630133903, 'sum_lstm_st1_lstm_st2_': 0.7910262570559677, 'mul_lstm_st1_net_st1_': 0.7889117196023603, 'sum_lstm_st1_net_st1_': 0.7889710336490864, 'mul_lstm_st1_net_st2_': 0.7897878088045329, 'sum_lstm_st1_net_st2_': 0.7900066719668853, 'mul_lstm_st2_net_st1_': 0.7896687626408825, 'sum_lstm_st2_net_st1_': 0.7896553197707121, 'mul_lstm_st2_net_st2_': 0.787241975336464, 'sum_lstm_st2_net_st2_': 0.7874246578814114, 'mul_net_st1_net_st2_': 0.7882716164984057, 'sum_net_st1_net_st2_': 0.788342970585755, 'lstm_st1': 0.7891890970318771, 'lstm_st2': 0.7878936453138599, 'net_st1': 0.7852172048423748, 'net_st2': 0.7841020168005646}\n",
      "\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.78    \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7802  \u001b[0m | \u001b[95m 0.8312  \u001b[0m | \u001b[95m 0.2092  \u001b[0m | \u001b[95m 4.523   \u001b[0m | \u001b[95m 42.19   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7794  \u001b[0m | \u001b[0m 0.9202  \u001b[0m | \u001b[0m 0.5957  \u001b[0m | \u001b[0m 4.185   \u001b[0m | \u001b[0m 44.37   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7804  \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2486  \u001b[0m | \u001b[95m 5.636   \u001b[0m | \u001b[95m 27.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.78    \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7804  \u001b[0m | \u001b[0m 0.9382  \u001b[0m | \u001b[0m 0.2901  \u001b[0m | \u001b[0m 5.715   \u001b[0m | \u001b[0m 27.88   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7804  \u001b[0m | \u001b[95m 0.9592  \u001b[0m | \u001b[95m 0.6951  \u001b[0m | \u001b[95m 5.983   \u001b[0m | \u001b[95m 26.01   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.807   \u001b[0m | \u001b[0m 0.1887  \u001b[0m | \u001b[0m 8.264   \u001b[0m | \u001b[0m 25.95   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7802  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.2172  \u001b[0m | \u001b[0m 4.026   \u001b[0m | \u001b[0m 25.24   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7802  \u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m 0.2467  \u001b[0m | \u001b[0m 4.706   \u001b[0m | \u001b[0m 39.73   \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.9592198134824175, 'feature_fraction': 0.6950958223863807, 'max_depth': 5.983418329296134, 'num_leaves': 26.01146033603542}\n",
      "bagging_fraction 0.9592198134824175\n",
      "feature_fraction 0.6950958223863807\n",
      "max_depth 5.983418329296134\n",
      "num_leaves 26.01146033603542\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 6, 'verbose': -1, 'num_leaves': 26, 'feature_fraction': 0.6950958223863807, 'bagging_fraction': 0.9592198134824175}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.792889\tvalid_1's auc: 0.781435\n",
      "[200]\ttraining's auc: 0.7931\tvalid_1's auc: 0.781246\n",
      "[300]\ttraining's auc: 0.793322\tvalid_1's auc: 0.781071\n",
      "[400]\ttraining's auc: 0.793481\tvalid_1's auc: 0.78105\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's auc: 0.792894\tvalid_1's auc: 0.781452\n",
      "roc_auc_score: 0.781451977428125\n",
      "lgb pass ==========================================\n",
      "\n",
      "Fold: 1 pass. Time 22.232518911361694 sec.\n",
      "=======================================================================================================\n",
      "\n",
      "\n",
      "mul_lstm_st1_lstm_st2_ 0.7862696927703807\n",
      "{'mul_lstm_st1_lstm_st2_net_st1_net_st2_': 0.786207969219749, 'sum_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7860095980650441, 'mul_lstm_st1_lstm_st2_net_st1_': 0.7861097981182724, 'sum_lstm_st1_lstm_st2_net_st1_': 0.7858452893661818, 'mul_lstm_st1_lstm_st2_net_st2_': 0.7858862413901568, 'sum_lstm_st1_lstm_st2_net_st2_': 0.7855916627689601, 'mul_lstm_st1_net_st1_net_st2_': 0.7854372300924733, 'sum_lstm_st1_net_st1_net_st2_': 0.7852863561468225, 'mul_lstm_st2_net_st1_net_st2_': 0.7855446381926712, 'sum_lstm_st2_net_st1_net_st2_': 0.7854078891966332, 'mul_lstm_st1_lstm_st2_': 0.7862696927703807, 'sum_lstm_st1_lstm_st2_': 0.786185835258427, 'mul_lstm_st1_net_st1_': 0.7837443110190123, 'sum_lstm_st1_net_st1_': 0.7835746679585536, 'mul_lstm_st1_net_st2_': 0.785270882111957, 'sum_lstm_st1_net_st2_': 0.7848964407904447, 'mul_lstm_st2_net_st1_': 0.7858221303606991, 'sum_lstm_st2_net_st1_': 0.7854952951095202, 'mul_lstm_st2_net_st2_': 0.7834677576007296, 'sum_lstm_st2_net_st2_': 0.7832211219636054, 'mul_net_st1_net_st2_': 0.7843719830641023, 'sum_net_st1_net_st2_': 0.784275193785723, 'lstm_st1': 0.7835246502533153, 'lstm_st2': 0.7838760466750359, 'net_st1': 0.781169414072427, 'net_st2': 0.7796228692391338}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7697  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7711  \u001b[0m | \u001b[95m 0.8312  \u001b[0m | \u001b[95m 0.2092  \u001b[0m | \u001b[95m 4.523   \u001b[0m | \u001b[95m 42.19   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7704  \u001b[0m | \u001b[0m 0.9202  \u001b[0m | \u001b[0m 0.5957  \u001b[0m | \u001b[0m 4.185   \u001b[0m | \u001b[0m 44.37   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7715  \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2486  \u001b[0m | \u001b[95m 5.636   \u001b[0m | \u001b[95m 27.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7701  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7715  \u001b[0m | \u001b[0m 0.9382  \u001b[0m | \u001b[0m 0.2901  \u001b[0m | \u001b[0m 5.715   \u001b[0m | \u001b[0m 27.88   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7694  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 6.049   \u001b[0m | \u001b[0m 25.74   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7714  \u001b[0m | \u001b[0m 0.891   \u001b[0m | \u001b[0m 0.3732  \u001b[0m | \u001b[0m 5.182   \u001b[0m | \u001b[0m 28.92   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7711  \u001b[0m | \u001b[0m 0.8031  \u001b[0m | \u001b[0m 0.2687  \u001b[0m | \u001b[0m 4.527   \u001b[0m | \u001b[0m 39.89   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7714  \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 0.2767  \u001b[0m | \u001b[0m 6.638   \u001b[0m | \u001b[0m 41.09   \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.9664885281600843, 'feature_fraction': 0.24863737747479334, 'max_depth': 5.636424704863906, 'num_leaves': 27.85149470692211}\n",
      "bagging_fraction 0.9664885281600843\n",
      "feature_fraction 0.24863737747479334\n",
      "max_depth 5.636424704863906\n",
      "num_leaves 27.85149470692211\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 6, 'verbose': -1, 'num_leaves': 28, 'feature_fraction': 0.24863737747479334, 'bagging_fraction': 0.9664885281600843}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.788349\tvalid_1's auc: 0.771171\n",
      "[200]\ttraining's auc: 0.788398\tvalid_1's auc: 0.771281\n",
      "[300]\ttraining's auc: 0.788464\tvalid_1's auc: 0.771362\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.788286\tvalid_1's auc: 0.771457\n",
      "roc_auc_score: 0.7714572432029179\n",
      "lgb pass ==========================================\n",
      "\n",
      "Fold: 2 pass. Time 20.9120512008667 sec.\n",
      "=======================================================================================================\n",
      "\n",
      "\n",
      "sum_lstm_st1_lstm_st2_ 0.7869022596627303\n",
      "{'mul_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7866247307743454, 'sum_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7867604006419974, 'mul_lstm_st1_lstm_st2_net_st1_': 0.7861055025809227, 'sum_lstm_st1_lstm_st2_net_st1_': 0.7862363329011874, 'mul_lstm_st1_lstm_st2_net_st2_': 0.7865848552822032, 'sum_lstm_st1_lstm_st2_net_st2_': 0.7867750965279581, 'mul_lstm_st1_net_st1_net_st2_': 0.7861027086887107, 'sum_lstm_st1_net_st1_net_st2_': 0.7862115236165967, 'mul_lstm_st2_net_st1_net_st2_': 0.7856957181511763, 'sum_lstm_st2_net_st1_net_st2_': 0.7858708086875509, 'mul_lstm_st1_lstm_st2_': 0.7869003141818072, 'sum_lstm_st1_lstm_st2_': 0.7869022596627303, 'mul_lstm_st1_net_st1_': 0.7837191473409093, 'sum_lstm_st1_net_st1_': 0.7839470776949633, 'mul_lstm_st1_net_st2_': 0.7862197875077003, 'sum_lstm_st1_net_st2_': 0.7864380831991076, 'mul_lstm_st2_net_st1_': 0.7848645190609878, 'sum_lstm_st2_net_st1_': 0.7850372336902967, 'mul_lstm_st2_net_st2_': 0.7843001189041878, 'sum_lstm_st2_net_st2_': 0.7844714939452286, 'mul_net_st1_net_st2_': 0.7847020285067008, 'sum_net_st1_net_st2_': 0.7848351553217003, 'lstm_st1': 0.7850869724685807, 'lstm_st2': 0.7841306437809422, 'net_st1': 0.7779516482887016, 'net_st2': 0.7812373472850551}\n",
      "\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7797  \u001b[0m | \u001b[0m 0.8312  \u001b[0m | \u001b[0m 0.2092  \u001b[0m | \u001b[0m 4.523   \u001b[0m | \u001b[0m 42.19   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7803  \u001b[0m | \u001b[95m 0.9202  \u001b[0m | \u001b[95m 0.5957  \u001b[0m | \u001b[95m 4.185   \u001b[0m | \u001b[95m 44.37   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 5.636   \u001b[0m | \u001b[0m 27.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7803  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7803  \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 0.5201  \u001b[0m | \u001b[0m 4.209   \u001b[0m | \u001b[0m 44.42   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7807  \u001b[0m | \u001b[95m 0.8954  \u001b[0m | \u001b[95m 0.8     \u001b[0m | \u001b[95m 5.648   \u001b[0m | \u001b[95m 45.0    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7803  \u001b[0m | \u001b[0m 0.9964  \u001b[0m | \u001b[0m 0.5122  \u001b[0m | \u001b[0m 6.868   \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7807  \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 0.788   \u001b[0m | \u001b[0m 5.5     \u001b[0m | \u001b[0m 44.26   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7796  \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 0.7243  \u001b[0m | \u001b[0m 12.98   \u001b[0m | \u001b[0m 24.15   \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.8954352185999643, 'feature_fraction': 0.8, 'max_depth': 5.647826857063357, 'num_leaves': 45.0}\n",
      "bagging_fraction 0.8954352185999643\n",
      "feature_fraction 0.8\n",
      "max_depth 5.647826857063357\n",
      "num_leaves 45.0\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 6, 'verbose': -1, 'num_leaves': 45, 'feature_fraction': 0.8, 'bagging_fraction': 0.8954352185999643}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.790146\tvalid_1's auc: 0.780589\n",
      "[200]\ttraining's auc: 0.79062\tvalid_1's auc: 0.780674\n",
      "[300]\ttraining's auc: 0.790766\tvalid_1's auc: 0.780782\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.789783\tvalid_1's auc: 0.780926\n",
      "roc_auc_score: 0.7809257290017496\n",
      "lgb pass ==========================================\n",
      "\n",
      "Fold: 3 pass. Time 20.381470680236816 sec.\n",
      "=======================================================================================================\n",
      "\n",
      "\n",
      "mul_lstm_st1_lstm_st2_ 0.7881991565550972\n",
      "{'mul_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7874208661433719, 'sum_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7874286066639777, 'mul_lstm_st1_lstm_st2_net_st1_': 0.7876110817411011, 'sum_lstm_st1_lstm_st2_net_st1_': 0.7877088651208208, 'mul_lstm_st1_lstm_st2_net_st2_': 0.7875194061321302, 'sum_lstm_st1_lstm_st2_net_st2_': 0.7874298374104245, 'mul_lstm_st1_net_st1_net_st2_': 0.7865622652171017, 'sum_lstm_st1_net_st1_net_st2_': 0.7866266076263595, 'mul_lstm_st2_net_st1_net_st2_': 0.7864496361179555, 'sum_lstm_st2_net_st1_net_st2_': 0.7864164816088359, 'mul_lstm_st1_lstm_st2_': 0.7881991565550972, 'sum_lstm_st1_lstm_st2_': 0.7881592192159095, 'mul_lstm_st1_net_st1_': 0.7855438597164636, 'sum_lstm_st1_net_st1_': 0.7856580353876813, 'mul_lstm_st1_net_st2_': 0.7869400994290371, 'sum_lstm_st1_net_st2_': 0.7868186679074625, 'mul_lstm_st2_net_st1_': 0.786869171760264, 'sum_lstm_st2_net_st1_': 0.7869824846960964, 'mul_lstm_st2_net_st2_': 0.7852666899352857, 'sum_lstm_st2_net_st2_': 0.7851926898688735, 'mul_net_st1_net_st2_': 0.7848131442299546, 'sum_net_st1_net_st2_': 0.784822017110702, 'lstm_st1': 0.786201273495799, 'lstm_st2': 0.7858170608510333, 'net_st1': 0.7821523533979111, 'net_st2': 0.7818646706450582}\n",
      "\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7746  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7765  \u001b[0m | \u001b[95m 0.8312  \u001b[0m | \u001b[95m 0.2092  \u001b[0m | \u001b[95m 4.523   \u001b[0m | \u001b[95m 42.19   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.9202  \u001b[0m | \u001b[0m 0.5957  \u001b[0m | \u001b[0m 4.185   \u001b[0m | \u001b[0m 44.37   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.777   \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2486  \u001b[0m | \u001b[95m 5.636   \u001b[0m | \u001b[95m 27.85   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7758  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.777   \u001b[0m | \u001b[0m 0.9382  \u001b[0m | \u001b[0m 0.2901  \u001b[0m | \u001b[0m 5.715   \u001b[0m | \u001b[0m 27.88   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7748  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 6.471   \u001b[0m | \u001b[0m 24.28   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.9682  \u001b[0m | \u001b[0m 0.5943  \u001b[0m | \u001b[0m 4.234   \u001b[0m | \u001b[0m 29.57   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.9249  \u001b[0m | \u001b[0m 0.166   \u001b[0m | \u001b[0m 4.348   \u001b[0m | \u001b[0m 39.69   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7768  \u001b[0m | \u001b[0m 0.8252  \u001b[0m | \u001b[0m 0.219   \u001b[0m | \u001b[0m 6.879   \u001b[0m | \u001b[0m 41.2    \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.9664885281600843, 'feature_fraction': 0.24863737747479334, 'max_depth': 5.636424704863906, 'num_leaves': 27.85149470692211}\n",
      "bagging_fraction 0.9664885281600843\n",
      "feature_fraction 0.24863737747479334\n",
      "max_depth 5.636424704863906\n",
      "num_leaves 27.85149470692211\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 6, 'verbose': -1, 'num_leaves': 28, 'feature_fraction': 0.24863737747479334, 'bagging_fraction': 0.9664885281600843}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.789483\tvalid_1's auc: 0.776548\n",
      "[200]\ttraining's auc: 0.789535\tvalid_1's auc: 0.776538\n",
      "[300]\ttraining's auc: 0.789602\tvalid_1's auc: 0.776465\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.789534\tvalid_1's auc: 0.776913\n",
      "roc_auc_score: 0.7769131735451018\n",
      "lgb pass ==========================================\n",
      "\n",
      "Fold: 4 pass. Time 20.41139054298401 sec.\n",
      "=======================================================================================================\n",
      "\n",
      "\n",
      "sum_lstm_st1_lstm_st2_net_st1_net_st2_ 0.7888249825783511\n",
      "{'mul_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7887970102494497, 'sum_lstm_st1_lstm_st2_net_st1_net_st2_': 0.7888249825783511, 'mul_lstm_st1_lstm_st2_net_st1_': 0.7884685811838039, 'sum_lstm_st1_lstm_st2_net_st1_': 0.7884666385386494, 'mul_lstm_st1_lstm_st2_net_st2_': 0.788512964956325, 'sum_lstm_st1_lstm_st2_net_st2_': 0.788556011224026, 'mul_lstm_st1_net_st1_net_st2_': 0.7883510590936379, 'sum_lstm_st1_net_st1_net_st2_': 0.7883755312644237, 'mul_lstm_st2_net_st1_net_st2_': 0.7879878336724423, 'sum_lstm_st2_net_st1_net_st2_': 0.78801845852266, 'mul_lstm_st1_lstm_st2_': 0.7886768611142496, 'sum_lstm_st1_lstm_st2_': 0.7887215896028864, 'mul_lstm_st1_net_st1_': 0.7860729565648148, 'sum_lstm_st1_net_st1_': 0.7860618890072955, 'mul_lstm_st1_net_st2_': 0.7884474179417558, 'sum_lstm_st1_net_st2_': 0.7884519267719367, 'mul_lstm_st2_net_st1_': 0.7876571057654731, 'sum_lstm_st2_net_st1_': 0.7876377051047325, 'mul_lstm_st2_net_st2_': 0.7861034244685529, 'sum_lstm_st2_net_st2_': 0.7860927613863299, 'mul_net_st1_net_st2_': 0.7874081019191694, 'sum_net_st1_net_st2_': 0.7873825002212388, 'lstm_st1': 0.7864916097269006, 'lstm_st2': 0.785377108241579, 'net_st1': 0.7818442318958214, 'net_st2': 0.7843490729437999}\n",
      "\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7844  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7859  \u001b[0m | \u001b[95m 0.8312  \u001b[0m | \u001b[95m 0.2092  \u001b[0m | \u001b[95m 4.523   \u001b[0m | \u001b[95m 42.19   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.786   \u001b[0m | \u001b[95m 0.9202  \u001b[0m | \u001b[95m 0.5957  \u001b[0m | \u001b[95m 4.185   \u001b[0m | \u001b[95m 44.37   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7858  \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 5.636   \u001b[0m | \u001b[0m 27.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7857  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7858  \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7862  \u001b[0m | \u001b[95m 0.8     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 9.205   \u001b[0m | \u001b[95m 45.0    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7847  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7861  \u001b[0m | \u001b[0m 0.8527  \u001b[0m | \u001b[0m 0.3666  \u001b[0m | \u001b[0m 6.998   \u001b[0m | \u001b[0m 44.61   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7836  \u001b[0m | \u001b[0m 0.9682  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 7.163   \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.8, 'feature_fraction': 0.1, 'max_depth': 9.20521786382577, 'num_leaves': 45.0}\n",
      "bagging_fraction 0.8\n",
      "feature_fraction 0.1\n",
      "max_depth 9.20521786382577\n",
      "num_leaves 45.0\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 9, 'verbose': -1, 'num_leaves': 45, 'feature_fraction': 0.1, 'bagging_fraction': 0.8}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.79057\tvalid_1's auc: 0.786252\n",
      "[200]\ttraining's auc: 0.790679\tvalid_1's auc: 0.786153\n",
      "[300]\ttraining's auc: 0.790755\tvalid_1's auc: 0.786185\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.790487\tvalid_1's auc: 0.786375\n",
      "roc_auc_score: 0.7863750901347174\n",
      "lgb pass ==========================================\n",
      "\n",
      "Fold: 5 pass. Time 21.673015594482422 sec.\n",
      "=======================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_val_true_parts_final  =[] \n",
    "y_val_pred_parts_final  =[] \n",
    "y_test_preds_final      =[] \n",
    "scors_list_final        =[]\n",
    "cut_list_final          =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m=6\n",
    "for i in range(m):\n",
    "    \n",
    "    start = time.time()\n",
    " \n",
    "    \n",
    "    y_val_lstm_st1 = y_val_pred_parts_lgbm[i]\n",
    "    y_val_lstm_st2 = y_val_pred_parts_lgbm2[i]\n",
    "    y_val_net_st1 = y_val_pred_parts_net[i]\n",
    "    y_val_net_st2 = y_val_pred_parts_net2[i]\n",
    "    \n",
    "    val_y = y_val_true_parts_net2[i]\n",
    "    \n",
    " \n",
    "\n",
    "    y_test_lstm_st1 = y_test_preds_lgbm[i]\n",
    "    y_test_lstm_st2 = y_test_preds_lgbm2[i]\n",
    "    y_test_net_st1 = y_test_preds_net[i]\n",
    "    y_test_net_st2 = y_test_preds_net2[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    a = y_val_lstm_st1.reshape(-1,1)\n",
    "    b = y_val_lstm_st2.reshape(-1,1)\n",
    "    c = y_val_net_st1.reshape(-1,1)\n",
    "    d = y_val_net_st2.reshape(-1,1)\n",
    "    \n",
    "    y_val_level2 = np.hstack((a,b,c,d))\n",
    "\n",
    "    \n",
    "    a = y_test_lstm_st1.reshape(-1,1)\n",
    "    b = y_test_lstm_st2.reshape(-1,1)\n",
    "    c = y_test_net_st1.reshape(-1,1)\n",
    "    d = y_test_net_st1.reshape(-1,1)\n",
    "    \n",
    "    y_test_level2 = np.hstack((a,b,c,d))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    models_dic = {'lstm_st1':y_val_lstm_st1, 'lstm_st2':y_val_lstm_st2, 'net_st1':y_val_net_st1, 'net_st2':y_val_net_st2,}\n",
    "    valid_data_dic = get_dics_results(models_dic)\n",
    "    \n",
    "    name, scores_dic = get_scores(val_y, valid_data_dic)\n",
    "    \n",
    "    \n",
    "    print(name,  scores_dic[name])    \n",
    "    print(scores_dic)    \n",
    "    print()\n",
    "    \n",
    "    models_dic = {'lstm_st1':y_test_lstm_st1, 'lstm_st2':y_test_lstm_st2, 'net_st1':y_test_net_st1, 'net_st2':y_test_net_st2,}\n",
    "    test_data_dic = get_dics_results(models_dic)\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(val_y, valid_data_dic[name], pos_label=1)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_threshold\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cut_list_final.append(optimal_threshold)     \n",
    "    y_val_true_parts_final.append(val_y)\n",
    "    y_val_pred_parts_final.append(valid_data_dic[name])\n",
    "    y_test_preds_final.append(test_data_dic[name])         \n",
    "            \n",
    "    scors_list_final.append(scores_dic[name])        \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    ypred_valid_lgbm_level2, ypred_test_lgbm_level2 = get_lgbm_result_level2(y_val_level2,  val_y, y_test_level2)            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start    \n",
    "\n",
    "    print('Fold:', i , 'pass. Time', duration,  'sec.')    \n",
    "    print('=======================================================================================================')\n",
    "    print()\n",
    "    print()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d75dac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7877827284819685,\n",
       " 0.7910344630133903,\n",
       " 0.7862696927703807,\n",
       " 0.7869022596627303,\n",
       " 0.7881991565550972,\n",
       " 0.7888249825783511]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scors_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1095e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa06892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136e3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "del scors_list_final[2]\n",
    "del y_val_pred_parts_final[2]\n",
    "del y_test_preds_final[2]\n",
    "del y_val_true_parts_final[2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6837ae9",
   "metadata": {},
   "source": [
    "del scors_list_final[2]\n",
    "del y_val_pred_parts_final[2]\n",
    "del y_test_preds_final[2]\n",
    "del y_val_true_parts_final[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f35d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc63cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b3d0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6346927673363487, 0.6320837123774419, 0.6354029282039451, 0.6343574410626113, 0.633854164159078]\n",
      "Final ROC AUC:     0.7885150386667665\n"
     ]
    }
   ],
   "source": [
    "y, y_vpred, test_preds = get_summary(scors_list_final, y_val_pred_parts_final, y_test_preds_final, y_val_true_parts_final, dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d787f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94abf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7877827284819685,\n",
       " 0.7910344630133903,\n",
       " 0.7869022596627303,\n",
       " 0.7881991565550972,\n",
       " 0.7888249825783511]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scors_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5af1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000014</td>\n",
       "      <td>0.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000020</td>\n",
       "      <td>0.101026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000027</td>\n",
       "      <td>0.022722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000043</td>\n",
       "      <td>0.054776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000049</td>\n",
       "      <td>0.014221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>3286660</td>\n",
       "      <td>0.012255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>3345810</td>\n",
       "      <td>0.016906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>3434512</td>\n",
       "      <td>0.020184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>3000786</td>\n",
       "      <td>0.013340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>3047012</td>\n",
       "      <td>0.011526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     score\n",
       "0       3000014  0.014008\n",
       "1       3000020  0.101026\n",
       "2       3000027  0.022722\n",
       "3       3000043  0.054776\n",
       "4       3000049  0.014221\n",
       "...         ...       ...\n",
       "499995  3286660  0.012255\n",
       "499996  3345810  0.016906\n",
       "499997  3434512  0.020184\n",
       "499998  3000786  0.013340\n",
       "499999  3047012  0.011526\n",
       "\n",
       "[500000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_preds.to_csv('./test_preds_5cut.csv', index=False)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d3ffdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val_true_parts_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575ca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410dcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac96ad5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "_ = plt.hist(y_vpred, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994588ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(y, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "073aff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00019038223224329828, 0.5283884825529577)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vpred.min(), y_vpred.max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c654550",
   "metadata": {},
   "source": [
    "from tqdm import tqdm\n",
    "levels=np.arange(0,0.05,0.0001)\n",
    "levels.shape\n",
    "\n",
    "best_rocauc = -1\n",
    "best_level = -1\n",
    "\n",
    "history = []\n",
    "for level in tqdm(list(levels)):\n",
    "    y_vpred__mod = np.where(y_vpred<level, 0, y_vpred)\n",
    "    level_roc = roc_auc_score(y, y_vpred__mod)\n",
    "    history.append(level_roc)\n",
    "    if level_roc > best_rocauc:\n",
    "        best_rocauc = level_roc\n",
    "        best_level = level\n",
    "        \n",
    "\n",
    "print(best_level)\n",
    "print()\n",
    "print(best_rocauc)\n",
    "print(roc_auc_score(y, y_vpred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dec4555a",
   "metadata": {},
   "source": [
    "plt.plot(history[:40])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07aee652",
   "metadata": {},
   "source": [
    "plt.plot(history[:15])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7dfab13",
   "metadata": {},
   "source": [
    "test_preds[\"score\"].min(), test_preds[\"score\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fa7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96225a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d7a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37f0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c0e8937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02594356, 0.02594356],\n",
       "       [0.15480709, 0.15480709],\n",
       "       [0.03645335, 0.03645335],\n",
       "       ...,\n",
       "       [0.01872797, 0.01872797],\n",
       "       [0.04643444, 0.04643444],\n",
       "       [0.02596505, 0.02596505]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = y_test_lstm_st1.reshape(-1,1)\n",
    "b=a.copy()\n",
    "c=np.hstack((a,b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e5922c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 2), (500000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, y_test_lstm_st1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ebe497",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | max_depth | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7844  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.59   \u001b[0m | \u001b[0m 36.57   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7859  \u001b[0m | \u001b[95m 0.8312  \u001b[0m | \u001b[95m 0.2092  \u001b[0m | \u001b[95m 4.523   \u001b[0m | \u001b[95m 42.19   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.786   \u001b[0m | \u001b[95m 0.9202  \u001b[0m | \u001b[95m 0.5957  \u001b[0m | \u001b[95m 4.185   \u001b[0m | \u001b[95m 44.37   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7858  \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 5.636   \u001b[0m | \u001b[0m 27.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7857  \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.4673  \u001b[0m | \u001b[0m 7.888   \u001b[0m | \u001b[0m 30.12   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7858  \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7862  \u001b[0m | \u001b[95m 0.8     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 9.205   \u001b[0m | \u001b[95m 45.0    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7847  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 45.0    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7861  \u001b[0m | \u001b[0m 0.8527  \u001b[0m | \u001b[0m 0.3666  \u001b[0m | \u001b[0m 6.998   \u001b[0m | \u001b[0m 44.61   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7836  \u001b[0m | \u001b[0m 0.9682  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 7.163   \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "=========================================================================\n",
      "{'bagging_fraction': 0.8, 'feature_fraction': 0.1, 'max_depth': 9.20521786382577, 'num_leaves': 45.0}\n",
      "bagging_fraction 0.8\n",
      "feature_fraction 0.1\n",
      "max_depth 9.20521786382577\n",
      "num_leaves 45.0\n",
      "\n",
      "================new params==================\n",
      "{'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.001, 'n_jobs': 8, 'seed': 15, 'max_depth': 9, 'verbose': -1, 'num_leaves': 45, 'feature_fraction': 0.1, 'bagging_fraction': 0.8}\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's auc: 0.79057\tvalid_1's auc: 0.786252\n",
      "[200]\ttraining's auc: 0.790679\tvalid_1's auc: 0.786153\n",
      "[300]\ttraining's auc: 0.790755\tvalid_1's auc: 0.786185\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.790487\tvalid_1's auc: 0.786375\n",
      "roc_auc_score: 0.7863750901347174\n",
      "lgb pass ==========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = y_val_lstm_st1.reshape(-1,1)\n",
    "b = y_val_lstm_st2.reshape(-1,1)\n",
    "c = y_val_net_st1.reshape(-1,1)\n",
    "d = y_val_net_st2.reshape(-1,1)\n",
    "\n",
    "y_val_level2 = np.hstack((a,b,c,d))\n",
    "\n",
    "\n",
    "a = y_test_lstm_st1.reshape(-1,1)\n",
    "b = y_test_lstm_st2.reshape(-1,1)\n",
    "c = y_test_net_st1.reshape(-1,1)\n",
    "d = y_test_net_st1.reshape(-1,1)\n",
    "\n",
    "y_test_level2 = np.hstack((a,b,c,d))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ypred_valid_lgbm_level2, ypred_test_lgbm_level2 = get_lgbm_result_level2(y_val_level2,  val_y, y_test_level2)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c2e2cbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7117910666061731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "\n",
    "\n",
    "\n",
    "tr_X,  tr_y, vl_X, vl_y = y_val_level2[:400000], val_y[:400000], y_val_level2[400000:], val_y[400000:]\n",
    "\n",
    "\n",
    "clf.fit(tr_X,  tr_y)\n",
    "\n",
    "\n",
    "calibrator = CalibratedClassifierCV(clf, cv='prefit')\n",
    "model=calibrator.fit(tr_X,  tr_y)\n",
    "\n",
    "#y_train_pred = model.predict_proba(X_tr)\n",
    "#y_test_pred = model.predict_proba(X_te)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_y_pred = model.predict_proba(vl_X)\n",
    "print(roc_auc_score(vl_y, val_y_pred[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f17171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97110323, 0.02889677],\n",
       "       [0.95906543, 0.04093457],\n",
       "       [0.97050172, 0.02949828],\n",
       "       ...,\n",
       "       [0.92962111, 0.07037889],\n",
       "       [0.94266306, 0.05733694],\n",
       "       [0.96295963, 0.03704037]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27d70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
